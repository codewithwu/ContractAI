import os
import re
from docx import Document
from typing import List, Dict, Any

class ContractParser:
    def __init__(self):
        self.supported_formats = ['.pdf', '.docx']
        # ä¸»æ¡æ¬¾æ¨¡å¼ï¼ˆåªåŒ¹é…ä¸»æ¡æ¬¾æ ‡é¢˜ï¼‰
        self.main_clause_patterns = [
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+æ¡',  # ä¸­æ–‡ä¸»æ¡æ¬¾
            r'^ç¬¬\d+æ¡',  # æ•°å­—ä¸»æ¡æ¬¾
            r'^ARTICLE',  # è‹±æ–‡ä¸»æ¡æ¬¾
            r'^SECTION',  # è‹±æ–‡ç« èŠ‚
        ]
        # å­æ¡æ¬¾æ¨¡å¼
        self.sub_clause_patterns = [
            r'^\d+\.\d+',  # 1.1, 2.3 ç­‰å­æ¡æ¬¾
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€',  # ä¸­æ–‡ç¼–å·
            r'^\d+ã€',  # æ•°å­—ç¼–å·
        ]
    
    def load_contract(self, file_path: str) -> List[Dict[str, Any]]:
        """åŠ è½½åˆåŒæ–‡ä»¶å¹¶æå–æ–‡æœ¬å†…å®¹"""
        try:
            doc = Document(file_path)
            content = []
            
            # æå–æ‰€æœ‰æ®µè½
            for i, paragraph in enumerate(doc.paragraphs):
                text = paragraph.text.strip()
                if text:
                    content.append({
                        'page_content': text,
                        'metadata': {
                            'source': file_path,
                            'paragraph_id': i,
                            'type': 'paragraph'
                        }
                    })
            
            return content
            
        except Exception as e:
            raise Exception(f"è§£æWordæ–‡æ¡£å¤±è´¥: {str(e)}")
    
    def split_into_clauses(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½æ¡æ¬¾åˆ†å‰² - å°†å­æ¡æ¬¾åˆå¹¶åˆ°ä¸»æ¡æ¬¾ä¸­"""
        clauses = []
        current_main_clause = []
        current_main_title = "åˆåŒå‰è¨€"
        current_sub_clauses = []
        
        for doc in documents:
            text = doc['page_content']
            metadata = doc['metadata']
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸»æ¡æ¬¾æ ‡é¢˜
            is_main_clause = self._is_main_clause(text)
            is_sub_clause = self._is_sub_clause(text)
            
            if is_main_clause:
                # ä¿å­˜ä¸Šä¸€ä¸ªä¸»æ¡æ¬¾åŠå…¶å­æ¡æ¬¾
                if current_main_clause or current_sub_clauses:
                    full_content = self._combine_clause_content(current_main_clause, current_sub_clauses)
                    clauses.append({
                        'page_content': full_content,
                        'metadata': {
                            **metadata,
                            'clause_title': current_main_title,
                            'type': 'main_clause',
                            'sub_clause_count': len(current_sub_clauses)
                        }
                    })
                
                # å¼€å§‹æ–°çš„ä¸»æ¡æ¬¾
                current_main_clause = [text]
                current_main_title = text
                current_sub_clauses = []
                
            elif is_sub_clause:
                # æ·»åŠ åˆ°å­æ¡æ¬¾åˆ—è¡¨
                current_sub_clauses.append(text)
            else:
                # æ™®é€šå†…å®¹ï¼Œæ·»åŠ åˆ°å½“å‰ä¸»æ¡æ¬¾æˆ–å­æ¡æ¬¾
                if current_sub_clauses:
                    # å¦‚æœæœ‰å­æ¡æ¬¾ï¼Œæ·»åŠ åˆ°æœ€åä¸€ä¸ªå­æ¡æ¬¾
                    if current_sub_clauses:
                        current_sub_clauses[-1] += "\n" + text
                else:
                    current_main_clause.append(text)
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ¡æ¬¾
        if current_main_clause or current_sub_clauses:
            full_content = self._combine_clause_content(current_main_clause, current_sub_clauses)
            clauses.append({
                'page_content': full_content,
                'metadata': {
                    **metadata,
                    'clause_title': current_main_title,
                    'type': 'main_clause',
                    'sub_clause_count': len(current_sub_clauses)
                }
            })
        
        return clauses
    
    def _is_main_clause(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»æ¡æ¬¾æ ‡é¢˜"""
        for pattern in self.main_clause_patterns:
            if re.match(pattern, text.strip()):
                return True
        return False
    
    def _is_sub_clause(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå­æ¡æ¬¾"""
        for pattern in self.sub_clause_patterns:
            if re.match(pattern, text.strip()):
                return True
        return False
    
    def _combine_clause_content(self, main_clause: List[str], sub_clauses: List[str]) -> str:
        """åˆå¹¶ä¸»æ¡æ¬¾å’Œå­æ¡æ¬¾å†…å®¹"""
        content_parts = []
        
        # æ·»åŠ ä¸»æ¡æ¬¾å†…å®¹
        if main_clause:
            content_parts.extend(main_clause)
        
        # æ·»åŠ å­æ¡æ¬¾å†…å®¹
        if sub_clauses:
            content_parts.extend(sub_clauses)
        
        return '\n'.join(content_parts)
    
    def analyze_risks(self, clauses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆ†ææ¯ä¸ªæ¡æ¬¾çš„é£é™©"""
        risk_keywords = {
            'è´¢åŠ¡é£é™©': ['æ”¯ä»˜', 'ä»˜æ¬¾', 'è¿çº¦é‡‘', 'ä»·æ ¼', 'é‡‘é¢', 'èµ”å¿', 'åˆ©æ¯'],
            'äº¤ä»˜é£é™©': ['äº¤ä»˜', 'éªŒæ”¶', 'æ ‡å‡†', 'æ—¶é—´', 'æœŸé™', 'å»¶è¿Ÿ', 'å°½å¿«'],
            'æ³•å¾‹é£é™©': ['äº‰è®®', 'è¯‰è®¼', 'ç®¡è¾–', 'çŸ¥è¯†äº§æƒ', 'ä¿å¯†', 'è´£ä»»'],
            'æ¨¡ç³Šæ¡æ¬¾': ['é€‚å½“', 'åˆç†', 'ç›¸å…³', 'é€šç”¨æ ‡å‡†', 'åå•†è§£å†³', 'è¡Œä¸šæ ‡å‡†'],
            'ä¸å¹³ç­‰æ¡æ¬¾': ['å•æ–¹', 'ç”²æ–¹æ‰€åœ¨åœ°', 'ä¹™æ–¹æ‰¿æ‹…å…¨éƒ¨è´£ä»»']
        }
        
        analyzed_clauses = []
        
        for clause in clauses:
            content = clause['page_content']
            risks_found = []
            
            for risk_type, keywords in risk_keywords.items():
                if any(keyword in content for keyword in keywords):
                    risks_found.append(risk_type)
            
            # è®¡ç®—é£é™©ç­‰çº§
            risk_level = "ä½é£é™©"
            if len(risks_found) >= 3:
                risk_level = "é«˜é£é™©"
            elif len(risks_found) >= 1:
                risk_level = "ä¸­é£é™©"
            
            analyzed_clauses.append({
                **clause,
                'risks': risks_found,
                'risk_level': risk_level
            })
        
        return analyzed_clauses





import os
import json
from typing import List, Dict, Any
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import re

class FixedLangChainContractAdvisor:
    def __init__(self, model: str = "qwen2.5:3b", base_url: str = "http://192.168.1.4:11434"):
        self.llm = ChatOllama(model=model, base_url=base_url, temperature=0.1)
        self.str_parser = StrOutputParser()
    
    def analyze_clause_with_llm(self, clause_content: str, clause_title: str, risks: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨ä¿®å¤ç‰ˆçš„LangChainåˆ†æåˆåŒæ¡æ¬¾"""
        try:
            # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆä¸åŒ…å«å˜é‡ï¼‰
            full_prompt = self._build_complete_prompt(clause_content, clause_title, risks)
            
            # åˆ›å»ºæç¤ºè¯æ¨¡æ¿ï¼ˆä¸åŒ…å«å˜é‡ï¼‰
            prompt = ChatPromptTemplate.from_template("{input}")
            
            # åˆ›å»ºå¤„ç†é“¾
            chain = prompt | self.llm | self.str_parser
            
            # æ‰§è¡Œåˆ†æ
            response = chain.invoke({"input": full_prompt})
            
            # è§£æå“åº”
            return self._parse_llm_response(response)
            
        except Exception as e:
            print(f"LangChainåˆ†æå¤±è´¥: {e}")
            return self._fallback_analysis(clause_content, risks)
    
    def _build_complete_prompt(self, clause_content: str, clause_title: str, risks: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆä¸åŒ…å«å˜é‡ï¼‰"""
        risk_descriptions = [f"- {risk['description']} ({risk['type']})" for risk in risks]
        risks_text = "\n".join(risk_descriptions) if risk_descriptions else "æœªå‘ç°æ˜æ˜¾é£é™©"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆåŒå®¡æŸ¥ä¸“å®¶ï¼Œæ“…é•¿è¯†åˆ«åˆåŒé£é™©å¹¶æä¾›å…·ä½“çš„ä¿®æ”¹å»ºè®®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š
{{
    "risk_analysis": "å¯¹æ¡æ¬¾é£é™©çš„è¯¦ç»†åˆ†æ",
    "specific_risks": ["å…·ä½“çš„é£é™©ç‚¹1", "é£é™©ç‚¹2"],
    "modification_suggestions": ["å…·ä½“çš„ä¿®æ”¹å»ºè®®1", "å»ºè®®2"],
    "legal_basis": "ç›¸å…³æ³•å¾‹ä¾æ®æˆ–å•†ä¸šè€ƒé‡", 
    "negotiation_tips": "è°ˆåˆ¤å»ºè®®",
    "risk_level": "ä½é£é™©|ä¸­é£é™©|é«˜é£é™©"
}}

è¦æ±‚ï¼š
1. åˆ†æè¦å…·ä½“ï¼ŒæŒ‡å‡ºå…·ä½“å“ªäº›è¯è¯­æˆ–å¥å­æœ‰é—®é¢˜
2. ä¿®æ”¹å»ºè®®è¦ç»™å‡ºå®Œæ•´çš„ä¿®æ”¹åæ–‡æœ¬
3. æ³•å¾‹ä¾æ®è¦å¼•ç”¨å…·ä½“çš„æ³•å¾‹æ¡æ–‡æˆ–å•†ä¸šå®è·µ
4. ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒä¸“ä¸šä½†æ˜“æ‡‚
5. é£é™©ç­‰çº§è¯„ä¼°è¦åŸºäºé£é™©ä¸¥é‡ç¨‹åº¦

è¯·åˆ†æä»¥ä¸‹åˆåŒæ¡æ¬¾ï¼š

ã€æ¡æ¬¾æ ‡é¢˜ã€‘{clause_title}

ã€æ¡æ¬¾å†…å®¹ã€‘
{clause_content}

ã€å·²è¯†åˆ«é£é™©ã€‘
{risks_text}

è¯·æä¾›ä¸“ä¸šçš„åˆåŒå®¡æŸ¥æ„è§ï¼š
"""
        return prompt
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMå“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            cleaned_response = response.strip()
            
            # å°è¯•æå–JSON
            json_match = re.search(r'\{[^{}]*\{.*\}[^{}]*\}|\{.*\}', cleaned_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                # è¿›ä¸€æ­¥æ¸…ç†JSONå­—ç¬¦ä¸²
                json_str = self._clean_json_string(json_str)
                
                result = json.loads(json_str)
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ["risk_analysis", "specific_risks", "modification_suggestions", 
                                 "legal_basis", "negotiation_tips", "risk_level"]
                if all(field in result for field in required_fields):
                    return result
            
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»å“åº”ä¸­æå–ä¿¡æ¯
            return self._extract_from_text(cleaned_response)
            
        except (json.JSONDecodeError, Exception) as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            return self._extract_from_text(response)
    
    def _clean_json_string(self, json_str: str) -> str:
        """æ¸…ç†JSONå­—ç¬¦ä¸²"""
        # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
        json_str = re.sub(r'```json\s*|\s*```', '', json_str)
        json_str = re.sub(r'```\s*|\s*```', '', json_str)
        
        # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤å°¾éšé€—å·
        json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤æ•°ç»„å°¾éšé€—å·
        
        return json_str.strip()
    
    def _extract_from_text(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯"""
        # ç®€å•çš„æ–‡æœ¬åˆ†ææ¥æå–ä¿¡æ¯
        risk_analysis = ""
        specific_risks = []
        modification_suggestions = []
        legal_basis = "åŸºäºæ ‡å‡†åˆåŒå®¡æŸ¥è§„èŒƒ"
        negotiation_tips = "å»ºè®®æ˜ç¡®å…³é”®å•†ä¸šæ¡æ¬¾"
        risk_level = "ä¸­é£é™©"
        
        # å°è¯•æå–é£é™©åˆ†æ
        lines = text.split('\n')
        for i, line in enumerate(lines):
            line = line.strip()
            if not line or line.startswith('{') or line.startswith('}'):
                continue
                
            if 'é£é™©' in line and len(line) > 10:
                risk_analysis = line
            elif 'å»ºè®®' in line or 'ä¿®æ”¹' in line:
                modification_suggestions.append(line)
            elif 'æ³•å¾‹' in line or 'ä¾æ®' in line:
                legal_basis = line
            elif 'è°ˆåˆ¤' in line or 'åå•†' in line:
                negotiation_tips = line
            elif 'é«˜é£é™©' in line:
                risk_level = "é«˜é£é™©"
            elif 'ä½é£é™©' in line:
                risk_level = "ä½é£é™©"
        
        # å¦‚æœæ²¡æ‰¾åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
        if not risk_analysis:
            risk_analysis = text[:300] + "..." if len(text) > 300 else text
        
        if not modification_suggestions:
            modification_suggestions = ["å»ºè®®ç”±ä¸“ä¸šæ³•åŠ¡äººå‘˜è¯¦ç»†å®¡æŸ¥"]
        
        return {
            "risk_analysis": risk_analysis,
            "specific_risks": specific_risks[:3],
            "modification_suggestions": modification_suggestions[:3],
            "legal_basis": legal_basis,
            "negotiation_tips": negotiation_tips,
            "risk_level": risk_level
        }
    
    def _fallback_analysis(self, clause_content: str, risks: List[Dict]) -> Dict[str, Any]:
        """å›é€€åˆ†ææ–¹æ¡ˆ"""
        risk_types = list(set([risk['type'] for risk in risks]))
        
        return {
            "risk_analysis": f"è¯†åˆ«åˆ°{len(risks)}ä¸ªé£é™©ç‚¹ï¼Œæ¶‰åŠï¼š{', '.join(risk_types)}",
            "specific_risks": [risk['description'] for risk in risks][:3],
            "modification_suggestions": self._generate_fallback_suggestions(risks),
            "legal_basis": "åŸºäºæ ‡å‡†åˆåŒå®¡æŸ¥è§„èŒƒ",
            "negotiation_tips": "å»ºè®®æ˜ç¡®å…³é”®å•†ä¸šæ¡æ¬¾",
            "risk_level": "é«˜é£é™©" if len(risks) > 3 else "ä¸­é£é™©" if risks else "ä½é£é™©"
        }
    
    def _generate_fallback_suggestions(self, risks: List[Dict]) -> List[str]:
        """ç”Ÿæˆå›é€€å»ºè®®"""
        suggestions = []
        
        for risk in risks:
            if any(word in risk['description'] for word in ['ä»˜æ¬¾', 'æ”¯ä»˜', 'é‡‘é¢']):
                suggestions.append("å»ºè®®æ˜ç¡®ä»˜æ¬¾æ—¶é—´å’Œæ¡ä»¶ï¼š'éªŒæ”¶åˆæ ¼å15ä¸ªå·¥ä½œæ—¥å†…æ”¯ä»˜å‰©ä½™æ¬¾é¡¹'")
                break
            elif any(word in risk['description'] for word in ['éªŒæ”¶', 'æ ‡å‡†', 'äº¤ä»˜']):
                suggestions.append("å»ºè®®å…·ä½“åŒ–éªŒæ”¶æ ‡å‡†ï¼šå‚ç…§å…·ä½“çš„æŠ€æœ¯è§„æ ¼å’ŒéªŒæ”¶ checklist")
                break
            elif 'è¿çº¦' in risk['description']:
                suggestions.append("å»ºè®®æ˜ç¡®è¿çº¦é‡‘è®¡ç®—æ–¹å¼å’Œä¸Šé™")
                break
            elif 'ç®¡è¾–' in risk['description']:
                suggestions.append("å»ºè®®é€‰æ‹©ä¸­ç«‹çš„ç®¡è¾–æ³•é™¢")
                break
        
        return suggestions if suggestions else ["å»ºè®®ç”±ä¸“ä¸šæ³•åŠ¡äººå‘˜å®¡æŸ¥æ­¤æ¡æ¬¾"]




class WorkingContractAI:
    def __init__(self, use_llm: bool = True, model: str = "qwen2.5:3b", base_url: str = "http://192.168.1.4:11434"):
        self.parser = ContractParser()
        self.use_llm = use_llm
        
        if use_llm:
            print(f"ğŸ¤– åˆå§‹åŒ–ä¿®å¤ç‰ˆLangChain Ollamaæ¨¡å‹: {model}")
            self.llm_advisor = FixedLangChainContractAdvisor(model=model, base_url=base_url)
        else:
            self.llm_advisor = None
        
        self.risk_rules = self._load_risk_rules()
    
    def _load_risk_rules(self) -> Dict[str, Any]:
        """åŠ è½½é£é™©è§„åˆ™"""
        return {
            'financial_risk': {
                'name': 'è´¢åŠ¡é£é™©',
                'keywords': ['æ”¯ä»˜', 'ä»˜æ¬¾', 'è¿çº¦é‡‘', 'ä»·æ ¼', 'é‡‘é¢', 'èµ”å¿', 'åˆ©æ¯', 'é¢„ä»˜æ¬¾', 'å°¾æ¬¾'],
                'patterns': [
                    (r'å‰©ä½™æ¬¾é¡¹.*éªŒæ”¶åˆæ ¼åæ”¯ä»˜', 'ä»˜æ¬¾æ¡ä»¶æ¨¡ç³Š'),
                    (r'æ”¯ä»˜.*æ€»ä»·.*50%', 'é¢„ä»˜æ¬¾æ¯”ä¾‹è¾ƒé«˜'),
                    (r'è¿çº¦é‡‘.*\d+\.?\d*%', 'è¿çº¦é‡‘æ¯”ä¾‹éœ€ç¡®è®¤')
                ]
            },
            'delivery_risk': {
                'name': 'äº¤ä»˜é£é™©', 
                'keywords': ['äº¤ä»˜', 'éªŒæ”¶', 'æ ‡å‡†', 'æ—¶é—´', 'æœŸé™', 'å»¶è¿Ÿ', 'å°½å¿«', 'éªŒæ”¶æ ‡å‡†'],
                'patterns': [
                    (r'æŒ‰ç…§.*æ ‡å‡†éªŒæ”¶', 'éªŒæ”¶æ ‡å‡†æ¨¡ç³Š'),
                    (r'å°½å¿«å¤„ç†', 'å“åº”æ—¶é—´ä¸æ˜ç¡®'),
                    (r'è¡Œä¸šé€šç”¨æ ‡å‡†', 'æ ‡å‡†å®šä¹‰ä¸æ¸…')
                ]
            },
            'legal_risk': {
                'name': 'æ³•å¾‹é£é™©',
                'keywords': ['äº‰è®®', 'è¯‰è®¼', 'ç®¡è¾–', 'çŸ¥è¯†äº§æƒ', 'ä¿å¯†', 'è´£ä»»', 'çº çº·'],
                'patterns': [
                    (r'ä¹™æ–¹æ‰¿æ‹…å…¨éƒ¨è´£ä»»', 'è´£ä»»åˆ†é…ä¸å‡'),
                    (r'ç”²æ–¹æ‰€åœ¨åœ°.*è¯‰è®¼', 'ç®¡è¾–åœ°å•æ–¹æœ‰åˆ©'),
                    (r'å‹å¥½åå•†è§£å†³', 'è§£å†³æ–¹å¼æ¨¡ç³Š')
                ]
            }
        }
    
    def analyze_contract(self, file_path: str, use_llm_for_high_risk: bool = True) -> Dict[str, Any]:
        """åˆ†æåˆåŒ"""
        try:
            print("ğŸ“– æ­£åœ¨è§£æåˆåŒ...")
            documents = self.parser.load_contract(file_path)
            clauses = self.parser.split_into_clauses(documents)
            
            print("ğŸ” æ­£åœ¨è¿›è¡Œé£é™©åˆ†æ...")
            analyzed_clauses = []
            
            for i, clause in enumerate(clauses):
                clause_title = clause['metadata']['clause_title']
                print(f"  åˆ†ææ¡æ¬¾ {i+1}/{len(clauses)}: {clause_title}")
                
                # åŸºç¡€é£é™©åˆ†æ
                basic_analysis = self._basic_risk_analysis(clause)
                
                # LLMæ·±åº¦åˆ†æï¼ˆåªå¯¹é«˜é£é™©æ¡æ¬¾æˆ–æ‰€æœ‰æ¡æ¬¾ï¼‰
                if self.use_llm and (not use_llm_for_high_risk or basic_analysis['risk_score'] < 70):
                    print(f"    ğŸ¤– ä½¿ç”¨LLMæ·±åº¦åˆ†æ: {clause_title}")
                    try:
                        llm_analysis = self.llm_advisor.analyze_clause_with_llm(
                            clause['page_content'],
                            clause_title,
                            basic_analysis['risks']
                        )
                        clause_analysis = {**basic_analysis, **llm_analysis}
                    except Exception as e:
                        print(f"    âš ï¸  LLMåˆ†æå¼‚å¸¸ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {e}")
                        clause_analysis = basic_analysis
                else:
                    clause_analysis = basic_analysis
                
                analyzed_clauses.append({
                    **clause,
                    **clause_analysis
                })
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(analyzed_clauses)
            return report
            
        except Exception as e:
            return {'error': f'åˆåŒåˆ†æå¤±è´¥: {str(e)}'}
    
    def _basic_risk_analysis(self, clause: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºç¡€é£é™©åˆ†æ"""
        content = clause['page_content']
        risks = self._detect_detailed_risks(content)
        risk_score = self._calculate_risk_score(risks)
        
        return {
            'risks': risks,
            'risk_score': risk_score,
            'review_status': 'å¾…å®¡æ ¸' if risks else 'ä½é£é™©'
        }
    
    def _detect_detailed_risks(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æµ‹è¯¦ç»†é£é™©"""
        risks = []
        
        for risk_id, rule in self.risk_rules.items():
            for keyword in rule['keywords']:
                if keyword in content:
                    risks.append({
                        'type': rule['name'],
                        'level': 'medium',
                        'description': f'å‘ç°å…³é”®è¯: {keyword}',
                        'position': self._find_keyword_position(content, keyword),
                        'category': risk_id
                    })
            
            for pattern, description in rule['patterns']:
                if re.search(pattern, content):
                    risks.append({
                        'type': rule['name'],
                        'level': 'high',
                        'description': description,
                        'position': 'æ¡æ¬¾å†…å®¹',
                        'category': risk_id
                    })
        
        return risks
    
    def _find_keyword_position(self, content: str, keyword: str) -> str:
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if keyword in line:
                return f"ç¬¬{i+1}è¡Œ"
        return "æ¡æ¬¾å†…å®¹"
    
    def _calculate_risk_score(self, risks: List[Dict[str, Any]]) -> int:
        if not risks:
            return 85
        
        high_risks = len([r for r in risks if r['level'] == 'high'])
        medium_risks = len([r for r in risks if r['level'] == 'medium'])
        
        base_score = 85
        score_reduction = high_risks * 20 + medium_risks * 10
        
        return max(30, base_score - score_reduction)
    
    def _generate_report(self, analysis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”ŸæˆæŠ¥å‘Š"""
        total_risks = sum(len(clause['risks']) for clause in analysis)
        high_risk_clauses = len([c for c in analysis if c['risk_score'] < 60])
        medium_risk_clauses = len([c for c in analysis if 60 <= c['risk_score'] < 75])
        
        overall_score = sum(c['risk_score'] for c in analysis) // len(analysis)
        
        return {
            'overall_risk_score': overall_score,
            'risk_level': self._get_risk_level(overall_score),
            'total_clauses': len(analysis),
            'total_risks_found': total_risks,
            'high_risk_clauses': high_risk_clauses,
            'medium_risk_clauses': medium_risk_clauses,
            'clauses_analysis': analysis,
            'summary': self._generate_summary(analysis),
            'llm_enhanced': self.use_llm,
            'timestamp': '2024-01-01 10:00:00'
        }
    
    def _get_risk_level(self, score: int) -> str:
        if score >= 80:
            return "ä½é£é™©"
        elif score >= 60:
            return "ä¸­é£é™©"
        else:
            return "é«˜é£é™©"
    
    def _generate_summary(self, analysis: List[Dict[str, Any]]) -> str:
        high_risk_count = len([c for c in analysis if c['risk_score'] < 60])
        
        if high_risk_count == 0:
            return "åˆåŒæ•´ä½“é£é™©å¯æ§ï¼Œå»ºè®®å…³æ³¨ä¸ªåˆ«ä¸­é£é™©æ¡æ¬¾ã€‚"
        elif high_risk_count <= 2:
            return "åˆåŒå­˜åœ¨å°‘é‡é«˜é£é™©æ¡æ¬¾ï¼Œå»ºè®®é‡ç‚¹å®¡æŸ¥ä»˜æ¬¾æ¡ä»¶ã€è¿çº¦è´£ä»»ç­‰æ¡æ¬¾ã€‚"
        else:
            return "åˆåŒå­˜åœ¨å¤šå¤„é«˜é£é™©æ¡æ¬¾ï¼Œå»ºè®®æ³•åŠ¡éƒ¨é—¨é‡ç‚¹å®¡æŸ¥ã€‚"

# æµ‹è¯•ä¿®å¤ç‰ˆ
def test_fixed_contract_ai():
    print("ğŸ”§ ä¿®å¤ç‰ˆ ContractAI with LangChain + Ollama")
    print("=" * 70)
    
    try:
        ai = WorkingContractAI(
            use_llm=True,
            model="qwen2.5:3b",
            base_url="http://192.168.1.4:11434"
        )
        
        test_file = "/home/cooper/githubProjects/ContractAI/words/test_contract.docx"
        
        print("å¼€å§‹åˆ†æåˆåŒ...")
        report = ai.analyze_contract(test_file, use_llm_for_high_risk=True)
        
        if 'error' in report:
            print(f"âŒ {report['error']}")
            return
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… å®¡æŸ¥å®Œæˆ!")
        print(f"ğŸ“Š æ•´ä½“é£é™©: {report['overall_risk_score']}/100 - {report['risk_level']}")
        print(f"ğŸ“‘ å®¡æŸ¥æ¡æ¬¾: {report['total_clauses']} ä¸ª")
        print(f"âš ï¸  é£é™©ç‚¹: {report['total_risks_found']} å¤„")
        print(f"ğŸ”´ é«˜é£é™©: {report['high_risk_clauses']} ä¸ª")
        print(f"ğŸŸ¡ ä¸­é£é™©: {report['medium_risk_clauses']} ä¸ª")
        
        # æ˜¾ç¤ºLLMåˆ†æçš„è¯¦ç»†ç»“æœ
        print(f"\nğŸ§  LLMæ·±åº¦åˆ†æç»“æœ:")
        print("-" * 70)
        
        llm_analyzed_clauses = [c for c in report['clauses_analysis'] if 'risk_analysis' in c and len(c['risk_analysis']) > 50]
        
        for clause in llm_analyzed_clauses[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªè¯¦ç»†åˆ†æ
            print(f"\nğŸ” {clause['metadata']['clause_title']} (é£é™©ç­‰çº§: {clause.get('risk_level', 'æœªçŸ¥')})")
            print(f"   ğŸ“ åˆ†æ: {clause['risk_analysis'][:200]}...")
            
            if clause.get('specific_risks'):
                print(f"   âš ï¸  å…·ä½“é£é™©:")
                for risk in clause['specific_risks'][:2]:
                    print(f"      â€¢ {risk}")
            
            if clause.get('modification_suggestions'):
                print(f"   ğŸ’¡ ä¿®æ”¹å»ºè®®:")
                for suggestion in clause['modification_suggestions'][:2]:
                    print(f"      â€¢ {suggestion}")
            
            if clause.get('negotiation_tips'):
                print(f"   ğŸ’¼ è°ˆåˆ¤å»ºè®®: {clause['negotiation_tips']}")
        
        print(f"\nğŸ“‹ å…± {len(llm_analyzed_clauses)} ä¸ªæ¡æ¬¾è·å¾—LLMæ·±åº¦åˆ†æ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_fixed_contract_ai()